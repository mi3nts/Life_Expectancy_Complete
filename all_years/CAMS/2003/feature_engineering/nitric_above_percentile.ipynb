{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301e79ed-101c-4611-8673-3f8ccb5d86c9",
   "metadata": {},
   "source": [
    "#### Notebook to feature engineer fraction of time nitric was above 75th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c2b3e-056c-44c2-8478-c0a1f70b6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conda environment Weather_Prediction\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8dc16-757a-4550-a199-232e63065c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_1=os.path.join('..','..','..','..','Weather_Data','CAMS','2003','2003_multi_level_26_variables.nc')\n",
    "ml_26_variables = xr.open_dataset(PATH_1) ## multilevel 26 variables\n",
    "ml_26_variables = ml_26_variables.squeeze(dim=\"model_level\") ## remove the model_level dimension\n",
    "ml_26_variables=ml_26_variables.drop_vars('model_level') ## the dropped dimension becomes a column, so remove that\n",
    "ml_26_variables['longitude'] = ml_26_variables['longitude']-360 ## necessary because of longitude data in multi-level case\n",
    "ml_26_variables\n",
    "nictric=ml_26_variables['hno3'] ## get only isoprene variable\n",
    "nitric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5af959-3aed-4afa-9396-f40ed39fa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "isoprene.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa7f8a-bd30-4e5c-a00e-3aeecb52bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_2=os.path.join('..','CAMS_79_variables_2003.pkl')\n",
    "get_data = pd.read_pickle(PATH_2) ## load the data with all variables\n",
    "get_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99b324-086c-455c-a792-46a2b17f9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_75 = get_data['hno3'].quantile(0.75) ## calculate 75th percentile\n",
    "print(percentile_75)\n",
    "threshold=percentile_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2fc3c-33ec-4dd3-bb4c-8d832ad6be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use county shapefile from 2008 as the shapefile before 2008 could not be found\n",
    "SHAPE_PATH=os.path.join('..','..','..','..','Shapefiles','county_shapefiles','2008_county_shapefile','tl_2008_us_county.shp')\n",
    "county_gdf = gpd.read_file(SHAPE_PATH)\n",
    "county_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05771ad-5321-4fb6-b0e6-a250cd0303eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_column=county_gdf['geometry']\n",
    "lat_lon=geometry_column.get_coordinates(index_parts=True)\n",
    "lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed1130-b42b-4f54-8580-a69b98ff544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_county(var):\n",
    "    \n",
    "    ''' Function to interpolate the values in a single county by taking a 100 or less latitude and longitude pair.\n",
    "        And then to find the fraction of time above percentile\n",
    "        Args:\n",
    "        --------\n",
    "             var (int): The index of the county in the shapefile.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            pm_above_df: Dataframe consisting the values of the variables interpolated in the county.\n",
    "    '''   \n",
    "    \n",
    "    \n",
    "    longitude= lat_lon.loc[(var), 'x']  # get the longitude\n",
    "    extract_val=len(longitude) ## find number of longitude that a shapfile has\n",
    "\n",
    "    ## if number of longitude or latitude is less than 100, that many lat-lon pairs will be extracted, if not, a 100 values\n",
    "    if extract_val < 100:\n",
    "        extract_val=extract_val\n",
    "    else:\n",
    "        extract_val=100\n",
    "\n",
    "    longitude=longitude[:extract_val]  ## extract first 100 values or values less than 100\n",
    "    latitude=lat_lon.loc[(var),'y']    ## get the latitude values\n",
    "    latitude=latitude[:extract_val]    ## extract first 100 values or values less than 100\n",
    "\n",
    "    lat_list=latitude.tolist()\n",
    "    lon_list=longitude.tolist()\n",
    "\n",
    "    ## find the corresponding values of the variables in the finer grid\n",
    "\n",
    "    year_avg_finer= nitric.interp(longitude=lon_list, latitude=lat_list)\n",
    "    \n",
    "## get only the 100 (or less) pair of latitude and longitude from the lat and lon list from the 100,000 (or less) rows\n",
    "    get_vals=[]\n",
    "\n",
    "    for i in range(0, extract_val):\n",
    "        row=year_avg_finer.isel(latitude=[i], longitude=[i])\n",
    "        row_df=row.to_dataframe()\n",
    "        get_vals.append(row_df)\n",
    "    \n",
    "    initial_df=pd.concat(get_vals)\n",
    "    summary = initial_df.groupby(\"valid_time\").mean([\"latitude\", \"longitude\"])\n",
    "    df=summary\n",
    "\n",
    "    total_rows=len(df)\n",
    "\n",
    "    c=0\n",
    "    for i in range(0, total_rows):\n",
    "        if df['hno3'].values[i] > threshold:\n",
    "            c=c+1\n",
    "\n",
    "## convert number to a fraction\n",
    "    frac_time=(c/total_rows)*100\n",
    "    pm_above_df=pd.DataFrame({'isoprene above percentile':[frac_time]})\n",
    "\n",
    "\n",
    "    return pm_above_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac2af8-746c-47f6-af89-6ca48f6ddecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(county_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bbc89d-c314-49cc-9f06-283108da76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## get the values for all counties\n",
    "\n",
    "df_list_below=[]\n",
    "\n",
    "for i in range(0,len(county_gdf)): ## loop for the all list of counties\n",
    "    try:\n",
    "        df_list_below.append(single_county(i))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f722038-4a8f-412f-8fec-bb33f99db914",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_df=pd.concat(df_list_below)\n",
    "final_df=concatenate_df.reset_index(drop=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa758775-ba51-4b18-915c-9bda1c0d2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets first create a fips column in the original shape file\n",
    "\n",
    "county_gdf['fips']=county_gdf['STATEFP'] + county_gdf['COUNTYFP']\n",
    "county_gdf.dtypes\n",
    "## convert the data type\n",
    "county_gdf['fips']=county_gdf['fips'].astype(str).astype(int)\n",
    "county_gdf.dtypes\n",
    "\n",
    "county_gdf = county_gdf.drop([ 'STATEFP','COUNTYFP','COUNTYNS','CNTYIDFP','NAMELSAD','LSAD','CLASSFP','MTFCC',\n",
    "                                 'CSAFP','CBSAFP','METDIVFP','FUNCSTAT'], axis=1)\n",
    "county_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95a928-22ef-49c8-a43b-e6e61e006f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=pd.merge(county_gdf, final_df, left_index=True, right_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8244303-430c-4e84-8294-3a5bd698c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df=merged_df.dropna()\n",
    "county_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14cd06b-caf6-42f9-8f95-f1ed45182f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into pandas dataframe without the geometry column\n",
    "pd.options.display.float_format = '{:.15f}'.format ## see 15 decimal places of the numbers\n",
    "county_var=pd.DataFrame(county_df.drop(columns='geometry')) \n",
    "county_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04093cc2-6dcd-48b4-8d31-d2a0f18e3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_var.to_pickle('nitric_above_percentile.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a04db0-4b7e-4a04-afd5-1b891691a8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
